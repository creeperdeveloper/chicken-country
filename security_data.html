<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Security Information - Chicken Country</title>
  <!-- Add no-cache headers to prevent caching -->
  <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate">
  <meta http-equiv="Pragma" content="no-cache">
  <meta http-equiv="Expires" content="0">
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
  <style>
    :root {
      --bg-color: #f8f9fa;
      --text-color: #212529;
      --card-bg: #ffffff;
      --header-bg: linear-gradient(135deg, #ff9a00, #ff6a00);
      --button-bg: #ff9a00;
      --button-hover: #ff6a00;
      --border-color: #e9ecef;
      --shadow-sm: 0 2px 8px rgba(0, 0, 0, 0.05);
      --shadow-md: 0 4px 12px rgba(0, 0, 0, 0.08);
      --shadow-lg: 0 8px 24px rgba(0, 0, 0, 0.12);
      --radius: 12px;
      --radius-sm: 8px;
      --radius-lg: 16px;
      --transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1);
      --accent: #ff6a00;
      --accent-light: #ff9a00;
      --muted: #6c757d;
      --link: #0066ff;
      --danger: #dc3545;
      --success: #28a745;
    }

    [data-theme="dark"] {
      --bg-color: #121212;
      --text-color: #f8f9fa;
      --card-bg: #1e1e1e;
      --header-bg: linear-gradient(135deg, #ff6a00, #ff4500);
      --button-bg: #ff6a00;
      --button-hover: #ff4500;
      --border-color: #2a2a2a;
      --shadow-sm: 0 2px 8px rgba(0, 0, 0, 0.2);
      --shadow-md: 0 4px 12px rgba(0, 0, 0, 0.3);
      --shadow-lg: 0 8px 24px rgba(0, 0, 0, 0.4);
      --accent: #ff4500;
      --accent-light: #ff6a00;
      --muted: #adb5bd;
      --link: #66a3ff;
    }

    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
      transition: var(--transition);
    }

    body {
      font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
      background-color: var(--bg-color);
      color: var(--text-color);
      line-height: 1.6;
      min-height: 100vh;
      font-weight: 400;
      letter-spacing: -0.01em;
      background-image: url('/placeholder.svg?height=1080&width=1920');
      background-attachment: fixed;
      background-size: cover;
      background-position: center;
    }

    header {
      background: var(--header-bg);
      padding: 1.25rem 2rem;
      display: flex;
      justify-content: space-between;
      align-items: center;
      box-shadow: var(--shadow-md);
      position: sticky;
      top: 0;
      z-index: 100;
      backdrop-filter: blur(10px);
    }

    .header-controls {
      display: flex;
      gap: 1rem;
      align-items: center;
    }

    h1 {
      font-weight: 700;
      font-size: 1.75rem;
      margin: 0;
      color: white;
      text-shadow: 0 1px 2px rgba(0, 0, 0, 0.1);
      letter-spacing: -0.02em;
    }

    h2 {
      font-weight: 600;
      font-size: 1.5rem;
      margin-bottom: 1.5rem;
      color: var(--accent);
      letter-spacing: -0.02em;
    }

    h3 {
      font-weight: 600;
      font-size: 1.25rem;
      margin-bottom: 0.75rem;
      letter-spacing: -0.01em;
    }

    .container {
      max-width: 1200px;
      margin: 2rem auto;
      padding: 0 2rem;
    }

    .section {
      margin-bottom: 2.5rem;
      padding: 2rem;
      background-color: var(--card-bg);
      border-radius: var(--radius);
      box-shadow: var(--shadow-md);
      border: 1px solid var(--border-color);
      backdrop-filter: blur(10px);
      background-color: rgba(255, 255, 255, 0.9);
    }

    [data-theme="dark"] .section {
      background-color: rgba(30, 30, 30, 0.9);
    }

    .back-link {
      display: inline-block;
      margin-bottom: 1.5rem;
      color: var(--link);
      text-decoration: none;
      font-weight: 500;
      transition: var(--transition);
    }

    .back-link:hover {
      color: var(--accent);
    }

    .login-container {
      max-width: 500px;
      margin: 5rem auto;
      padding: 2rem;
      background-color: rgba(255, 255, 255, 0.9);
      border-radius: var(--radius);
      box-shadow: var(--shadow-lg);
      border: 1px solid var(--border-color);
      text-align: center;
      backdrop-filter: blur(10px);
      position: relative;
      overflow: hidden;
      display: block; /* Explicitly set display */
    }

    .login-header {
      background: var(--header-bg);
      margin: -2rem -2rem 2rem -2rem;
      padding: 1.5rem 2rem;
      display: flex;
      justify-content: space-between;
      align-items: center;
      color: white;
    }

    .login-header h1 {
      margin: 0;
      font-size: 1.5rem;
    }

    [data-theme="dark"] .login-container {
      background-color: rgba(30, 30, 30, 0.9);
    }

    .login-form {
      display: flex;
      flex-direction: column;
      gap: 1.5rem;
      margin-top: 2rem;
    }

    .form-group {
      display: flex;
      flex-direction: column;
      gap: 0.5rem;
      text-align: left;
    }

    .form-group label {
      font-weight: 500;
      color: var(--accent);
    }

    .form-group input {
      padding: 0.75rem 1rem;
      border: 1px solid var(--border-color);
      border-radius: var(--radius-sm);
      font-family: inherit;
      background-color: var(--bg-color);
      color: var(--text-color);
    }

    .form-group input:focus {
      outline: none;
      border-color: var(--accent);
      box-shadow: 0 0 0 2px rgba(255, 106, 0, 0.2);
    }

    .error-message {
      color: var(--danger);
      font-size: 0.9rem;
      margin-top: 0.5rem;
    }

    button {
      padding: 0.75rem 1rem;
      background-color: var(--button-bg);
      color: white;
      border: none;
      border-radius: var(--radius-sm);
      font-weight: 500;
      cursor: pointer;
      transition: var(--transition);
    }

    button:hover {
      background-color: var(--button-hover);
      transform: translateY(-2px);
      box-shadow: var(--shadow-md);
    }

    .login-button {
      width: 100%;
      padding: 0.875rem;
      font-size: 1rem;
      margin-top: 1rem;
    }

    .security-content {
      display: none; /* Explicitly set display */
    }

    .security-list {
      display: grid;
      grid-template-columns: repeat(auto-fill, minmax(320px, 1fr));
      gap: 1.5rem;
      margin-top: 1.5rem;
    }

    .security-card {
      background-color: var(--card-bg);
      border: 1px solid var(--border-color);
      border-radius: var(--radius-sm);
      padding: 1.5rem;
      box-shadow: var(--shadow-sm);
      transition: var(--transition);
      position: relative;
      overflow: hidden;
    }

    .security-card::before {
      content: '';
      position: absolute;
      top: 0;
      left: 0;
      width: 4px;
      height: 100%;
      background: var(--accent);
      opacity: 0.8;
    }

    .security-card:hover {
      transform: translateY(-5px);
      box-shadow: var(--shadow-lg);
    }

    .security-card h3 {
      color: var(--accent);
      margin-bottom: 1rem;
    }

    .security-card p {
      margin-bottom: 0.75rem;
      font-size: 0.95rem;
    }

    .security-card p:last-child {
      margin-bottom: 0;
    }

    .security-card p strong {
      font-weight: 600;
      color: var(--accent-light);
    }

    .security-image {
      width: 100%;
      height: 180px;
      object-fit: cover;
      border-radius: var(--radius-sm);
      margin-bottom: 1rem;
    }

    .theme-toggle,
    .language-toggle {
      background-color: rgba(255, 255, 255, 0.2);
      backdrop-filter: blur(10px);
      color: white;
      border: none;
      border-radius: var(--radius-sm);
      cursor: pointer;
      display: flex;
      align-items: center;
      justify-content: center;
      transition: var(--transition);
      box-shadow: var(--shadow-sm);
    }

    .theme-toggle {
      width: 40px;
      height: 40px;
      position: relative;
      border-radius: 50%;
    }

    .language-toggle {
      padding: 0.5rem 1rem;
      font-weight: 500;
      font-size: 0.875rem;
    }

    .theme-toggle:hover,
    .language-toggle:hover {
      background-color: rgba(255, 255, 255, 0.3);
      transform: translateY(-2px);
      box-shadow: var(--shadow-md);
    }

    .theme-toggle .icon {
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      width: 20px;
      height: 20px;
      color: white;
    }

    .theme-toggle .sun {
      opacity: 1;
      display: block;
    }

    .theme-toggle .moon {
      opacity: 0;
      display: none;
    }

    [data-theme="dark"] .theme-toggle .sun {
      opacity: 0;
      display: none;
    }

    [data-theme="dark"] .theme-toggle .moon {
      opacity: 1;
      display: block;
    }

    .back-to-home {
      display: inline-block;
      margin-top: 1.5rem;
      color: var(--link);
      text-decoration: none;
      font-size: 0.9rem;
      transition: var(--transition);
    }

    .back-to-home:hover {
      color: var(--accent);
      text-decoration: underline;
    }

    @media (max-width: 768px) {
      .security-list {
        grid-template-columns: 1fr;
      }

      .container {
        padding: 0 1rem;
        margin: 1.5rem auto;
      }

      .login-container {
        margin: 2rem auto;
        padding: 1.5rem;
        width: 90%;
      }

      .login-header {
        padding: 1rem;
        margin: -1.5rem -1.5rem 1.5rem -1.5rem;
      }

      .section {
        padding: 1.5rem;
      }

      header {
        padding: 1rem;
      }

      h1 {
        font-size: 1.5rem;
      }
    }

    /* Animations */
    @keyframes fadeIn {
      from {
        opacity: 0;
        transform: translateY(10px);
      }

      to {
        opacity: 1;
        transform: translateY(0);
      }
    }

    .login-container {
      animation: fadeIn 0.5s ease-out forwards;
    }

    .security-card {
      animation: fadeIn 0.5s ease-out forwards;
    }

    .security-card:nth-child(2) {
      animation-delay: 0.1s;
    }

    .security-card:nth-child(3) {
      animation-delay: 0.2s;
    }

    .security-card:nth-child(4) {
      animation-delay: 0.3s;
    }

    .security-card:nth-child(5) {
      animation-delay: 0.4s;
    }

    .security-card:nth-child(6) {
      animation-delay: 0.5s;
    }

    .security-card:nth-child(7) {
      animation-delay: 0.6s;
    }
    
    /* Add logout button styles */
    .logout-button {
      margin-top: 1.5rem;
      padding: 0.5rem 1rem;
      background-color: var(--danger);
      color: white;
      border: none;
      border-radius: var(--radius-sm);
      font-weight: 500;
      cursor: pointer;
      transition: var(--transition);
    }
    
    .logout-button:hover {
      background-color: #b02a37;
      transform: translateY(-2px);
      box-shadow: var(--shadow-md);
    }
  </style>
</head>

<body>
  <div class="login-container" id="loginContainer">
    <div class="login-header">
      <h1 id="login-title">Security Information</h1>
      <div class="header-controls">
        <button class="language-toggle" id="loginLanguageToggle">日本語</button>
        <button id="loginThemeToggle" class="theme-toggle" aria-label="Toggle dark mode">
          <svg class="icon sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
            fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
            <circle cx="12" cy="12" r="5"></circle>
            <line x1="12" y1="1" x2="12" y2="3"></line>
            <line x1="12" y1="21" x2="12" y2="23"></line>
            <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
            <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
            <line x1="1" y1="12" x2="3" y2="12"></line>
            <line x1="21" y1="12" x2="23" y2="12"></line>
            <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
            <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
          </svg>
          <svg class="icon moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
            fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
            <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
          </svg>
        </button>
      </div>
    </div>
    
    <p id="login-description">Please enter the password to access security information.</p>

    <form class="login-form" id="loginForm">
      <div class="form-group">
        <label for="password" id="password-label">Password</label>
        <input type="password" id="password" name="password" required>
        <div class="error-message" id="errorMessage"></div>
      </div>
      <button type="submit" id="login-button" class="login-button">Access Information</button>
    </form>
    
    <a href="index.html" class="back-to-home" id="login-back-link">← Back to Home</a>
  </div>

  <div class="container security-content" id="securityContent">
    <header>
      <h1>Chicken Country</h1>
      <div class="header-controls">
        <button class="language-toggle" id="languageToggle">日本語</button>
        <button id="themeToggle" class="theme-toggle" aria-label="Toggle dark mode">
          <svg class="icon sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
            fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
            <circle cx="12" cy="12" r="5"></circle>
            <line x1="12" y1="1" x2="12" y2="3"></line>
            <line x1="12" y1="21" x2="12" y2="23"></line>
            <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
            <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
            <line x1="1" y1="12" x2="3" y2="12"></line>
            <line x1="21" y1="12" x2="23" y2="12"></line>
            <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
            <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
          </svg>
          <svg class="icon moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
            fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
            <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
          </svg>
        </button>
      </div>
    </header>

    <div class="section">
      <a href="index.html" class="back-link" id="back-link">← Back to Home</a>
      <h2 id="security-title">Security Information</h2>

      <div class="security-list" id="securityList">
        <!-- Security items will be displayed here -->
      </div>
      
      <!-- Add a logout button -->
      <button id="logoutButton" class="logout-button">Logout</button>
    </div>
  </div>

  <script>
    // Force page reload when navigating back to this page
    window.addEventListener('pageshow', function(event) {
      if (event.persisted) {
        // Page is loaded from cache (back/forward navigation)
        window.location.reload();
      }
    });
    
    // Immediately execute this code to ensure it runs as soon as possible
    (function() {
      console.log("Script starting execution");
      
      // Language translations
      const translations = {
        en: {
          loginTitle: 'Security Information',
          loginDescription: 'Please enter the password to access security information.',
          passwordLabel: 'Password',
          loginButton: 'Access Information',
          backLink: '← Back to Home',
          securityTitle: 'Security Information',
          overview: 'Overview',
          creator: 'Creator',
          notes: 'Notes',
          languageButton: '日本語',
          incorrectPassword: 'Incorrect password. Please try again.',
          logoutButton: 'Logout'
        },
        ja: {
          loginTitle: 'セキュリティ情報',
          loginDescription: 'セキュリティ情報にアクセスするにはパスワードを入力してください。',
          passwordLabel: 'パスワード',
          loginButton: '情報にアクセス',
          backLink: '← ホームに戻る',
          securityTitle: 'セキュリティ情報',
          overview: '概要',
          creator: '作成者',
          notes: 'メモ',
          languageButton: 'English',
          incorrectPassword: 'パスワードが間違っています。もう一度お試しください。',
          logoutButton: 'ログアウト'
        }
      };

      // Current language - default to English if not set
      let currentLanguage = localStorage.getItem('language') || 'en';
      console.log("Current language:", currentLanguage);

      // Password hash and salt (instead of storing the plain password)
      // This is the hash of "chicken is top! (main_super_2)" with salt "ChickenCountrySalt"
      const passwordHash = "7e89fb4360d593b0e1c39d6036aa54717b246a6c6e7b7f51cd9dc1c498c1f273";
      const passwordSalt = "ChickenCountrySalt";

      // Simple hash function using SHA-256
      async function hashPassword(password, salt) {
        const encoder = new TextEncoder();
        const data = encoder.encode(password + salt);
        const hashBuffer = await crypto.subtle.digest('SHA-256', data);
        const hashArray = Array.from(new Uint8Array(hashBuffer));
        const hashHex = hashArray.map(b => b.toString(16).padStart(2, '0')).join('');
        return hashHex;
      }

      // Security information as objects
      const securityItems = [
        {
          id: 1,
          name: "オートドアセキュリティ",
          nameEn: "Auto Door Security",
          image: "/placeholder.svg?height=180&width=320",
          overview: "キーカードであくドアでネザライトブロックで出来ている",
          overviewEn: "Door made of netherite blocks that opens with a key card",
          creator: "yutty & Flimsy",
          notes: " ",
          notesEn: " "
        }, {
          id: 2,
          name: "落とし穴セキュリティ",
          nameEn: "Pitfall Security",
          image: "/placeholder.svg?height=180&width=320",
          overview: "プレイヤーを確実に落として下から攻撃できるようにするセキュリティ",
          overviewEn: "Security system that reliably drops players and allows attacks from below",
          creator: "FlimsyDeer05833 / creeper_developer",
          notes: " ",
          notesEn: " "
        },
        {
          id: 3,
          name: "無限迷路セキュリティ",
          nameEn: "Infinite Maze Security",
          image: "/placeholder.svg?height=180&width=320",
          overview: "制御ルームからクリアできるか無限ループするかを設定できるセキュリティ",
          overviewEn: "Security system where you can set whether it can be cleared or loops infinitely from the control room",
          creator: "FlimsyDeer05833 / creeper_developer",
          notes: " ",
          notesEn: " "
        },
        {
          id: 4,
          name: "NoEscapeセキュリティ",
          nameEn: "NoEscape Security",
          image: "/placeholder.svg?height=180&width=320",
          overview: "一度入ったらレバーなどを使わない限り戻れないセキュリティ",
          overviewEn: "Security system where once entered, you cannot return without using levers, etc.",
          creator: "FlimsyDeer05833 / creeper_developer",
          notes: " ",
          notesEn: " "
        }, {
          id: 5,
          name: "手動認証セキュリティ",
          nameEn: "Manual Authentication Security",
          image: "/placeholder.svg?height=180&width=320",
          overview: "プレイヤーが実際に認証を行ってドアがあくセキュリティ 認証失敗した場合は下に落とすセキュリティも開発中",
          overviewEn: "Security system where players actually perform authentication to open doors. A system to drop players if authentication fails is also under development",
          creator: "FlimsyDeer05833 / creeper_developer",
          notes: " ",
          notesEn: " "
        }, {
          id: 6,
          name: "無限ループ迷路セキュリティ2",
          nameEn: "Infinite Loop Maze Security 2",
          image: "/placeholder.svg?height=180&width=320",
          overview: "制御ルームからクリアできるかを設定できる迷路",
          overviewEn: "Maze where you can set whether it can be cleared from the control room",
          creator: "FlimsyDeer05833 / creeper_developer",
          notes: " ",
          notesEn: " "
        }, {
          id: 7,
          name: "4Fセキュリティ 作成中",
          nameEn: "4F Security (In Development)",
          image: "/placeholder.svg?height=180&width=320",
          overview: " ",
          overviewEn: " ",
          creator: " ",
          notes: " ",
          notesEn: " "
        },
      ];

      // Get DOM elements - with error handling
      function getElement(id) {
        const element = document.getElementById(id);
        if (!element) {
          console.error(`Element with ID "${id}" not found`);
          return null;
        }
        return element;
      }

      const loginContainer = getElement('loginContainer');
      const securityContent = getElement('securityContent');
      const errorMessage = getElement('errorMessage');
      const loginForm = getElement('loginForm');
      const logoutButton = getElement('logoutButton');

      // Display security items
      function renderSecurityItems() {
        console.log("Rendering security items");
        const securityList = getElement('securityList');
        if (!securityList) {
          console.error('Security list element not found');
          return;
        }

        securityList.innerHTML = '';

        securityItems.forEach(item => {
          const securityCard = document.createElement('div');
          securityCard.className = 'security-card';

          const name = currentLanguage === 'en' ? item.nameEn : item.name;
          const overview = currentLanguage === 'en' ? item.overviewEn : item.overview;
          const notes = currentLanguage === 'en' ? item.notesEn : item.notes;
          const overviewLabel = translations[currentLanguage].overview;
          const creatorLabel = translations[currentLanguage].creator;
          const notesLabel = translations[currentLanguage].notes;

          securityCard.innerHTML = `
            <img src="${item.image}" alt="${name}" class="security-image">
            <h3>${name}</h3>
            <p><strong>${overviewLabel}:</strong> ${overview}</p>
            <p><strong>${creatorLabel}:</strong> ${item.creator}</p>
            <p><strong>${notesLabel}:</strong> ${notes}</p>
          `;
          securityList.appendChild(securityCard);
        });
      }

      // Update language function
      function updateLanguage() {
        console.log("Updating language to:", currentLanguage);
        try {
          // Update UI text
          const elements = {
            'login-title': translations[currentLanguage].loginTitle,
            'login-description': translations[currentLanguage].loginDescription,
            'password-label': translations[currentLanguage].passwordLabel,
            'login-button': translations[currentLanguage].loginButton,
            'login-back-link': translations[currentLanguage].backLink,
            'back-link': translations[currentLanguage].backLink,
            'security-title': translations[currentLanguage].security�# Aaronliu0208/devops
# kubernetes/kubernetes-in-action/chapter-11/README.md
# 11. Understanding Kubernetes internals

## 11.1 Understanding the architecture

### 11.1.1 The distributed nature of Kubernetes components

![](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

### 11.1.2 How kubernetes components communicate

![](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

### 11.1.3 How the components are run

![](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

## 11.2 How controllers cooperate

### 11.2.1 Understanding the control plane

![](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

### 11.2.2 Understanding what a running pod is

![](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

### 11.2.3 Inter-pod networking

![](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

### 11.2.4 How services are implemented

![](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

### 11.2.5 Running highly available clusters

![](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

## 11.3 Understanding what happens when you create a pod

### 11.3.1 What happens in the API server

![](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

### 11.3.2 What the Scheduler does

![](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

### 11.3.3 What Kubelet does

![](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

### 11.3.4 What the Container Runtime does

![](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

### 11.3.5 What happens after the container is started

![](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

## 11.4 Understanding how kubectl works

### 11.4.1 Understanding how kubectl communicates with the API server

![](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

### 11.4.2 Understanding how API objects are updated

![](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

## 11.5 Summary

![](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

# 11. Understanding Kubernetes internals

In this chapter, we'll look at how Kubernetes components work together to enable the deployment and management of applications. We'll also look at how containers are run and how they're made to work together.

## 11.1 Understanding the architecture

Let's start by looking at the high-level architecture of a Kubernetes cluster. A Kubernetes cluster is split into two parts:

- The Kubernetes Control Plane
- The (worker) nodes

The Control Plane is what controls and makes the whole system tick. It consists of multiple components that can run on a single master node or be split across multiple nodes and replicated to ensure high availability. These components are:

- The Kubernetes API Server, which you and the other Control Plane components communicate with
- The Scheduler, which schedules your apps (assigns a worker node to each deployable component of your application)
- The Controller Manager, which performs cluster-level functions, such as replicating components, keeping track of worker nodes, handling node failures, and so on
- etcd, a reliable distributed data store that persistently stores the cluster configuration.

The worker nodes are the machines that run your containerized applications. The task of running, monitoring, and providing services to your applications is done by:

- Docker, rkt, or another container runtime, which runs your containers
- The Kubelet, which talks to the API server and manages containers on its node
- The Kubernetes Service Proxy (kube-proxy), which load-balances network traffic between application components

The following figure shows the components that make up a Kubernetes cluster.

![Figure 11.1 Components of a Kubernetes cluster](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

### 11.1.1 The distributed nature of Kubernetes components

All these components together represent a complete Kubernetes system. They can all run on a single node, but they're usually distributed across multiple nodes: one master node running the Control Plane components and multiple worker nodes running the actual applications.

The Control Plane components can also be replicated for high availability. This is shown in the following figure.

![Figure 11.2 A highly available Kubernetes cluster with multiple master nodes](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

#### UNDERSTANDING THE CONTROL PLANE COMPONENTS

The Control Plane components keep control of the cluster and make it function. They keep track of all Kubernetes objects in the system, and continuously try to make the actual state of the system converge toward the desired state specified by the user.

The API server is at the center of the Control Plane components. All other components interact with it, but they don't talk to each other directly. The API server is the only component that connects to etcd. All other components use the API server to update the cluster state.

#### UNDERSTANDING THE WORKER NODE COMPONENTS

The worker nodes are where your applications run. All the applications you deploy to Kubernetes run on worker nodes. To run and manage a container on a node, Kubernetes requires a container runtime to be installed on the node. Docker is the most widely used container runtime, but Kubernetes also supports rkt and any implementation of the Kubernetes Container Runtime Interface (CRI).

The Kubelet and the Kubernetes Service Proxy (kube-proxy) run on each node. The Kubelet is the component responsible for everything running on a worker node. Its initial job is to register the node it's running on by creating a Node resource in the API server. Then it continuously monitors the API server for Pods that have been scheduled to the node, and starts the pod's containers. It then constantly monitors running containers and reports their status, events, and resource consumption to the API server.

The Kubelet is also the component that runs the container liveness probes, restarting containers when the probes fail. It also terminates containers when their Pod is deleted from the API server and notifies the server when they terminate.

The kube-proxy makes sure clients can connect to the services you define through the Kubernetes API. The kube-proxy makes this possible by managing iptables rules (or using other mechanisms) on the node to redirect connection requests to one of the pods backing the service.

### 11.1.2 How kubernetes components communicate

The Kubernetes API server is the central component used by both the clients and the other components. But the components don't all communicate with the API server in the same way.

#### COMMUNICATING THROUGH THE KUBERNETES API

Clients and other components talk to the API server by sending REST HTTP requests to it. But some components, such as the Scheduler, Controller Manager, and etcd, need to be notified of changes to the API objects they care about as soon as those changes occur. Having them continuously send requests to the API server to check if anything has changed would be incredibly inefficient, so the API server allows clients to watch for changes instead of having to poll for them.

#### COMPONENTS COMMUNICATING THROUGH DIRECT CONNECTIONS

Not all communication between components goes through the API server. The best example is when the API server needs to talk to the Kubelet. The API server connects to the Kubelet when a client sends a request to the API server that requires communicating with the Kubelet. Examples include:

- When a client sends a request to attach to a running container (kubectl attach)
- When a client requests a set of logs (kubectl logs)
- When a client requests port forwarding to a pod (kubectl port-forward)

In these cases, the API server acts as a proxy between the client and the Kubelet. This allows the client to access the Kubelet without having direct access to the node itself.

### 11.1.3 How the components are run

The components that make up a Kubernetes system can be run as regular applications on the operating system, but they're usually run as system components.

#### RUNNING COMPONENTS AS SYSTEM COMPONENTS

On traditional Linux systems, system components are usually run as system services through systemd, Upstart, or other init systems. But Kubernetes components can also be deployed and managed by Kubernetes itself. The Control Plane components can be deployed as pods through static pod manifests or through the API server. The Kubelet is the only component that always needs to be run as a system service, because it's the component that then runs all the other components deployed as pods.

#### RUNNING COMPONENTS IN PODS

Running the Control Plane components as pods has several advantages. The main one is that you can use Kubernetes itself to manage them. This means you can use all the features of Kubernetes to manage the components, such as automatic restarts, automatic upgrades, and so on.

The following figure shows the Control Plane components running as pods on the master node.

![Figure 11.3 Control Plane components running as pods on the master node](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

## 11.2 How controllers cooperate

Now that you understand the components that make up a Kubernetes system, let's look at how they work together to make the system function.

### 11.2.1 Understanding the control plane

The Control Plane is the brain of the Kubernetes system. It's responsible for keeping track of all Kubernetes objects in the system and continuously making sure the actual state of the system converges toward the desired state specified by the user.

The Control Plane consists of the following components:

- The Kubernetes API Server
- The Scheduler
- The Controller Manager
- etcd

#### THE KUBERNETES API SERVER

The API server is the central component of the Kubernetes Control Plane. All other components and clients communicate with the API server. The API server provides a RESTful API that clients can use to create, update, delete, and retrieve Kubernetes objects. The API server is the only component that connects to etcd, the distributed data store that persistently stores the cluster configuration.

The API server performs the following functions:

- It validates and configures data for the API objects, such as pods, services, and so on.
- It serves as the frontend to the cluster's shared state through which all other components interact.

#### THE SCHEDULER

The Scheduler is responsible for scheduling pods onto nodes. When a new pod is created, the Scheduler selects a node for the pod to run on. The Scheduler takes into account the resource requirements of the pod, the characteristics of the nodes, and other constraints and policies when making scheduling decisions.

The Scheduler performs the following functions:

- It watches for newly created pods that have no node assigned.
- It selects a node for the pod to run on.
- It updates the pod definition with the selected node name.

#### THE CONTROLLER MANAGER

The Controller Manager is responsible for running controllers that regulate the state of the system. A controller is a control loop that watches the shared state of the cluster through the API server and makes changes attempting to move the current state toward the desired state.

The Controller Manager includes the following controllers:

- The Node Controller: Responsible for noticing and responding when nodes go down.
- The Replication Controller: Responsible for maintaining the correct number of pods for every replication controller object in the system.
- The Endpoints Controller: Populates the Endpoints object (that is, joins Services & Pods).
- Service Account & Token Controllers: Create default accounts and API access tokens for new namespaces.

#### ETCD

etcd is a distributed key-value store that Kubernetes uses to store all its data. It's the only stateful component in the Control Plane. All other components are stateless and can be restarted without losing any data.

etcd provides a reliable way to store data across a cluster of machines. It's designed to be highly available and to provide consistent data storage even in the face of machine failures.

### 11.2.2 Understanding what a running pod is

A pod is the basic building block in Kubernetes. It's the smallest and simplest unit in the Kubernetes object model that you create or deploy. A pod represents a running process on your cluster.

A pod encapsulates an application container (or, in some cases, multiple containers), storage resources, a unique network IP, and options that govern how the container(s) should run. A pod represents a unit of deployment: a single instance of an application in Kubernetes, which might consist of either a single container or a small number of containers that are tightly coupled and that share resources.

#### THE ANATOMY OF A POD

A pod is a group of one or more containers, with shared storage/network, and a specification for how to run the containers. A pod's contents are always co-located and co-scheduled, and run in a shared context. A pod models an application-specific "logical host" - it contains one or more application containers which are relatively tightly coupled.

The shared context of a pod is a set of Linux namespaces, cgroups, and potentially other facets of isolation - the same things that isolate a Docker container. Within a pod's context, the individual applications may have further sub-isolations applied.

In terms of Docker concepts, a pod is similar to a group of Docker containers with shared namespaces and shared filesystem volumes.

#### HOW CONTAINERS SHARE RESOURCES IN A POD

Containers within a pod share an IP address and port space, and can find each other via localhost. They can also communicate with each other using standard inter-process communications like SystemV semaphores or POSIX shared memory. Containers in different pods have distinct IP addresses and can not communicate by IPC without special configuration.

Containers within a pod also have access to shared volumes, which are defined as part of a pod and are made available to be mounted into each container's filesystem.

### 11.2.3 Inter-pod networking

In Kubernetes, each pod gets its own IP address. This means you do not need to explicitly create links between pods and you almost never need to deal with mapping container ports to host ports. This creates a clean, backwards-compatible model where pods can be treated much like VMs or physical hosts from the perspectives of port allocation, naming, service discovery, load balancing, application configuration, and migration.

Kubernetes imposes the following fundamental requirements on any networking implementation:

- All containers can communicate with all other containers without NAT.
- All nodes can communicate with all containers (and vice-versa) without NAT.
- The IP that a container sees itself as is the same IP that others see it as.

Given these constraints, there are a number of ways to implement pod networking. The most common approach is to use a Container Network Interface (CNI) plugin, which is responsible for allocating IP addresses to pods and enabling pod-to-pod communication across nodes.

### 11.2.4 How services are implemented

A Kubernetes Service is an abstraction which defines a logical set of Pods and a policy by which to access them. The set of Pods targeted by a Service is usually determined by a selector.

For example, consider a stateless image-processing backend which is running with 3 replicas. Those replicas are fungible—frontends do not care which backend they use. While the actual Pods that compose the backend set may change, the frontend clients should not need to be aware of that, nor should they need to keep track of the set of backends themselves.

The Service abstraction enables this decoupling.

#### IMPLEMENTING SERVICE LOAD BALANCING

Kubernetes Services are implemented using a combination of virtual IPs and kube-proxy. The virtual IP is a cluster-internal IP address that is assigned to the Service. When a client connects to this IP, the connection is load-balanced to one of the pods backing the Service.

The kube-proxy component that runs on each node is responsible for implementing this load balancing. It does this by setting up iptables rules (or using other mechanisms, depending on the mode it's running in) that redirect connection requests to the Service's virtual IP to one of the pods backing the Service.

#### SERVICE DISCOVERY

Kubernetes supports two primary modes of finding a Service - environment variables and DNS.

When a Pod is run on a Node, the kubelet adds a set of environment variables for each active Service. It supports both Docker links compatible variables and simpler {SVCNAME}_SERVICE_HOST and {SVCNAME}_SERVICE_PORT variables, where the Service name is upper-cased and dashes are converted to underscores.

The second (and recommended) way to discover Services is using the Kubernetes DNS server. The Kubernetes DNS server is a cluster add-on that provides DNS records for Kubernetes Services. When enabled, the DNS server watches the Kubernetes API for new Services and creates a set of DNS records for each one. If DNS has been enabled throughout the cluster then all Pods should be able to do name resolution of Services automatically.

### 11.2.5 Running highly available clusters

For production use, it's recommended to run a highly available Kubernetes cluster with multiple master nodes. This ensures that if one master node fails, the cluster can continue to function.

A highly available Kubernetes cluster has multiple master nodes, each running a copy of the Control Plane components. The etcd data store is also replicated across multiple nodes to ensure high availability.

The following figure shows a highly available Kubernetes cluster with multiple master nodes.

![Figure 11.4 A highly available Kubernetes cluster with multiple master nodes](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

## 11.3 Understanding what happens when you create a pod

Let's now look at what happens when you create a pod in Kubernetes. This will help you understand how the different components work together to make the system function.

### 11.3.1 What happens in the API server

When you create a pod (or any other Kubernetes object), you're sending a REST HTTP request to the Kubernetes API server. The API server processes the request, validates it, and persists the object to etcd.

The API server performs the following steps when processing a request to create a pod:

1. It authenticates the client and authorizes the request.
2. It validates the pod specification.
3. It creates a Pod object in etcd.
4. It notifies clients watching for pod creations.

#### VALIDATING AND PERSISTING THE POD

The API server validates the pod specification to ensure it's well-formed. It checks that the pod has a valid namespace, that the specified containers have valid image names, that the resource requirements are valid, and so on.

If the pod specification is valid, the API server creates a Pod object in etcd. At this point, the pod exists in the system, but it's not running yet. The pod's status is set to "Pending".

#### NOTIFYING CLIENTS

After the pod is created in etcd, the API server notifies all clients that are watching for pod creations. One of these clients is the Scheduler, which is responsible for assigning nodes to pods.

### 11.3.2 What the Scheduler does

The Scheduler is watching the API server for newly created pods that don't have a node assigned. When it sees such a pod, it selects a node for the pod to run on and updates the pod definition with the selected node name.

The Scheduler performs the following steps when scheduling a pod:

1. It filters the nodes to find those that are feasible for the pod (for example, nodes that have enough resources).
2. It ranks the feasible nodes to find the best one for the pod.
3. It updates the pod definition with the selected node name.

#### FILTERING NODES

The Scheduler first filters the nodes to find those that are feasible for the pod. A node is feasible if it meets all the pod's requirements. For example, if the pod requires 2 CPUs and 4 GB of memory, a node with only 1 CPU or 2 GB of memory would not be feasible.

The Scheduler also checks other constraints, such as node selectors, node affinity, taints and tolerations, and so on.

#### RANKING NODES

After filtering out infeasible nodes, the Scheduler ranks the remaining nodes to find the best one for the pod. The ranking is based on various factors, such as the amount of resources available on the node, the number of pods already running on the node, and so on.

The Scheduler uses a scoring system to rank the nodes. Each scoring function assigns a score to each node, and the node with the highest total score is selected.

#### UPDATING THE POD

After selecting a node, the Scheduler updates the pod definition with the selected node name. This is done by sending a patch request to the API server to update the pod's spec.nodeName field.

At this point, the pod is scheduled to a node, but it's still not running. The pod's status is still "Pending".

### 11.3.3 What Kubelet does

The Kubelet on the selected node is watching the API server for pods that are scheduled to its node. When it sees such a pod, it starts the pod's containers.

The Kubelet performs the following steps when starting a pod:

1. It creates the pod's network namespace.
2. It sets up the pod's volumes.
3. It pulls the pod's container images.
4. It starts the pod's containers.
5. It updates the pod's status in the API server.

#### CREATING THE POD'S NETWORK NAMESPACE

The Kubelet first creates a network namespace for the pod. This is a Linux namespace that isolates the pod's network stack from the host and from other pods.

The Kubelet then calls the CNI plugin to set up the pod's network. The CNI plugin assigns an IP address to the pod and sets up the necessary routes and iptables rules to enable pod-to-pod communication.

#### SETTING UP THE POD'S VOLUMES

The Kubelet then sets up the pod's volumes. It mounts the volumes specified in the pod definition into the pod's namespace. These volumes can be used by the pod's containers to store data.

#### PULLING THE POD'S CONTAINER IMAGES

The Kubelet then pulls the container images specified in the pod definition. It uses the container runtime (such as Docker) to pull the images from the specified registry.

#### STARTING THE POD'S CONTAINERS

After pulling the images, the Kubelet starts the pod's containers. It uses the container runtime to create and start the containers in the pod's namespace.

#### UPDATING THE POD'S STATUS

Finally, the Kubelet updates the pod's status in the API server. It sets the pod's status to "Running" and updates other status fields, such as the pod's IP address, the container statuses, and so on.

### 11.3.4 What the Container Runtime does

The Container Runtime is responsible for running the containers. It's used by the Kubelet to pull images, create containers, and manage their lifecycle.

The Container Runtime performs the following functions:

- It pulls container images from a registry.
- It creates and starts containers.
- It manages the container lifecycle (starting, stopping, removing).
- It provides a way to interact with running containers (exec, logs, etc.).

#### PULLING CONTAINER IMAGES

When the Kubelet needs to run a container, it first asks the Container Runtime to pull the container image from a registry. The Container Runtime downloads the image and stores it locally.

#### CREATING AND STARTING CONTAINERS

After pulling the image, the Container Runtime creates a container from the image. It sets up the container's filesystem, network, and other resources according to the container configuration.

Then, it starts the container by running the command specified in the container configuration.

#### MANAGING THE CONTAINER LIFECYCLE

The Container Runtime is also responsible for managing the container lifecycle. It can start, stop, and remove containers as requested by the Kubelet.

#### INTERACTING WITH RUNNING CONTAINERS

The Container Runtime provides a way to interact with running containers. It allows executing commands in a container, retrieving container logs, and so on.

### 11.3.5 What happens after the container is started

After the container is started, the Kubelet continuously monitors it and reports its status to the API server. If the container crashes, the Kubelet restarts it according to the pod's restart policy.

The Kubelet also runs the container liveness and readiness probes specified in the pod definition. If a liveness probe fails, the Kubelet restarts the container. If a readiness probe fails, the Kubelet marks the container as not ready, which affects service load balancing.

## 11.4 Understanding how kubectl works

kubectl is the command-line interface for running commands against Kubernetes clusters. It allows you to create, inspect, update, and delete Kubernetes objects.

### 11.4.1 Understanding how kubectl communicates with the API server

kubectl communicates with the Kubernetes API server using the Kubernetes API. It sends REST HTTP requests to the API server to perform operations on Kubernetes objects.

When you run a kubectl command, the following steps occur:

1. kubectl parses the command-line arguments and flags.
2. It constructs a REST HTTP request based on the command.
3. It sends the request to the API server.
4. It processes the response from the API server and displays the result.

#### AUTHENTICATING TO THE API SERVER

kubectl uses a kubeconfig file to find the information it needs to choose a cluster and communicate with the API server of a cluster. By default, kubectl looks for a file named config in the $HOME/.kube directory. You can specify other kubeconfig files by setting the KUBECONFIG environment variable or by using the --kubeconfig flag.

The kubeconfig file contains the following information:

- Cluster information: The URL of the API server and the certificate authority data.
- User information: The client certificate data, client key data, or token for authenticating to the API server.
- Context information: A combination of a cluster, a user, and a namespace.

kubectl uses this information to authenticate to the API server when sending requests.

#### SENDING REQUESTS TO THE API SERVER

After authenticating, kubectl sends REST HTTP requests to the API server to perform operations on Kubernetes objects. The type of request depends on the command you're running:

- GET requests for commands that retrieve information (get, describe, etc.)
- POST requests for commands that create objects (create, apply, etc.)
- PUT or PATCH requests for commands that update objects (edit, apply, etc.)
- DELETE requests for commands that delete objects (delete, etc.)

#### PROCESSING THE RESPONSE

kubectl processes the response from the API server and displays the result in the format specified by the output flags (-o json, -o yaml, -o wide, etc.).

For commands that watch for changes (like kubectl get pods --watch), kubectl keeps the connection open and continuously processes and displays the updates received from the API server.

### 11.4.2 Understanding how API objects are updated

When you update a Kubernetes object using kubectl, the update is not applied directly to the object in etcd. Instead, kubectl sends a patch request to the API server, which then applies the patch to the object.

There are three types of patches in Kubernetes:

- JSON Patch: A sequence of operations that describe how to modify the resource.
- Strategic Merge Patch: A partial representation of the object that is merged with the existing object.
- JSON Merge Patch: A partial representation of the object that is merged with the existing object according to the JSON Merge Patch standard.

kubectl uses Strategic Merge Patch by default for most operations, as it provides the most intuitive behavior for updating Kubernetes objects.

#### OPTIMISTIC CONCURRENCY CONTROL

Kubernetes uses optimistic concurrency control to prevent conflicts when multiple clients try to update the same object simultaneously. Each object has a resourceVersion field that is updated every time the object is modified.

When you update an object, kubectl includes the current resourceVersion in the patch request. The API server checks if the resourceVersion in the request matches the current resourceVersion of the object. If they match, the update is applied. If they don't match, the request is rejected with a conflict error.

This ensures that if another client has modified the object since you last retrieved it, your update will not overwrite those changes.

## 11.5 Summary

In this chapter, we've looked at how Kubernetes components work together to enable the deployment and management of applications. We've also looked at how containers are run and how they're made to work together.

We've covered the following topics:

- The architecture of a Kubernetes cluster, including the Control Plane and worker nodes
- How Kubernetes components communicate with each other
- How controllers cooperate to maintain the desired state of the system
- What happens when you create a pod, from the API server to the Container Runtime
- How kubectl works and how it communicates with the API server

Understanding these internals can help you better understand how Kubernetes works and how to troubleshoot issues when they arise.

# Aaronliu0208/devops
# kubernetes/kubernetes-in-action/chapter-10/README.md
# 10. Stateful Sets: deploying replicated stateful applications

## 10.1 Replicating stateful pods

### 10.1.1 Understanding the problems with stateful pods

![](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

### 10.1.2 Running multiple replicas with separate storage for each

![](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

### 10.1.3 Providing a stable identity for each pod

![](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

## 10.2 Understanding StatefulSets

### 10.2.1 Comparing StatefulSets with ReplicaSets

![](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

### 10.2.2 Providing a stable network identity

![](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

### 10.2.3 Providing stable dedicated storage to each pod

![](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

### 10.2.4 Understanding StatefulSet guarantees

![](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

## 10.3 Using a StatefulSet

### 10.3.1 Creating the app and container image

![](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

### 10.3.2 Deploying the app through a StatefulSet

![](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

### 10.3.3 Playing with your pods

![](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

### 10.3.4 Discovering peers in a StatefulSet

![](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

### 10.3.5 Understanding how StatefulSets deal with node failures

![](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

### 10.3.6 Updating a StatefulSet

![](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

## 10.4 Summary

![](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

# 10. Stateful Sets: deploying replicated stateful applications

In this chapter, we'll explore how to deploy stateful applications in Kubernetes. We'll look at the challenges of running stateful applications in a distributed environment and how Kubernetes addresses these challenges with StatefulSets.

## 10.1 Replicating stateful pods

Let's start by understanding the challenges of replicating stateful pods and how Kubernetes addresses them.

### 10.1.1 Understanding the problems with stateful pods

Stateful applications, unlike stateless ones, maintain data that must persist across pod restarts and rescheduling. This presents several challenges in a distributed environment like Kubernetes:

1. **Persistent Storage**: Each instance of a stateful application typically needs its own persistent storage that survives pod restarts.

2. **Network Identity**: Stateful applications often need a stable network identity. For example, in a database cluster, each node might need to be addressable by a specific hostname.

3. **Ordering**: The startup and shutdown order of pods might be important. For instance, a master database node might need to be started before slave nodes.

4. **Scaling**: Scaling stateful applications is more complex than scaling stateless ones because each instance might have its own state that needs to be considered.

Let's consider a simple example of a stateful application: a database. Each database pod needs:

- Its own persistent storage
- A stable network identity so other pods can connect to it
- Possibly a specific startup order (master before slaves)

If we were to use a ReplicaSet to deploy such an application, we'd run into several issues:

- ReplicaSets don't provide stable network identities for pods
- ReplicaSets don't guarantee the order of pod startup and shutdown
- ReplicaSets don't provide a way to attach persistent storage to specific pods

This is where StatefulSets come in. They're designed specifically to address these challenges.

### 10.1.2 Running multiple replicas with separate storage for each

One of the key requirements for stateful applications is that each pod needs its own persistent storage. This is different from stateless applications, where all pods can share the same storage or don't need persistent storage at all.

In Kubernetes, persistent storage is provided through Persistent Volumes (PVs) and Persistent Volume Claims (PVCs). A PV is a piece of storage in the cluster, while a PVC is a request for storage by a user.

For a stateful application with multiple replicas, each pod needs its own PVC. This is illustrated in the following figure:

![Figure 10.1 Each pod in a stateful application needs its own persistent storage](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

In this figure, we have three pods, each with its own PVC. The PVCs are bound to PVs, which provide the actual storage.

StatefulSets make it easy to create multiple pods, each with its own PVC. They do this by using a PVC template, similar to how a ReplicaSet uses a pod template. When a StatefulSet creates a pod, it also creates a PVC for that pod using the PVC template.

### 10.1.3 Providing a stable identity for each pod

Another key requirement for stateful applications is that each pod needs a stable network identity. This is important for applications where pods need to communicate with each other directly, such as in a database cluster.

In a ReplicaSet, pods are given random names and IP addresses. If a pod is deleted and recreated, it gets a new name and IP address. This is fine for stateless applications, but it's a problem for stateful applications where pods need to be addressable by a specific name.

StatefulSets solve this problem by giving each pod a stable, unique name. The name is based on the StatefulSet name and the pod's ordinal index. For example, if a StatefulSet is named "web", the pods will be named "web-0", "web-1", "web-2", and so on.

This is illustrated in the following figure:

![Figure 10.2 StatefulSets provide stable identities for pods](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

In this figure, we have a StatefulSet named "web" with three replicas. The pods are named "web-0", "web-1", and "web-2". If "web-1" is deleted, a new pod will be created with the same name, ensuring a stable identity.

## 10.2 Understanding StatefulSets

Now that we understand the challenges of running stateful applications in Kubernetes, let's look at how StatefulSets address these challenges.

### 10.2.1 Comparing StatefulSets with ReplicaSets

StatefulSets and ReplicaSets are both controllers that manage pods, but they have some key differences:

1. **Pod Identity**: In a ReplicaSet, pods are interchangeable. In a StatefulSet, each pod has a unique, stable identity.

2. **Pod Creation and Deletion**: ReplicaSets create all pods in parallel. StatefulSets create pods in sequence, starting from 0. They delete pods in reverse order, starting from the highest ordinal.

3. **Scaling**: When scaling a ReplicaSet, all new pods are created in parallel. When scaling a StatefulSet, pods are created one at a time, in order.

4. **Storage**: ReplicaSets don't provide a way to attach persistent storage to specific pods. StatefulSets can create PVCs for each pod.

The following table summarizes these differences:

| Feature | ReplicaSet | StatefulSet |
|---------|------------|-------------|
| Pod Identity | Random | Stable, unique |
| Pod Creation | Parallel | Sequential |
| Pod Deletion | Parallel | Reverse sequential |
| Scaling | Parallel | Sequential |
| Storage | Not managed | Can create PVCs |

### 10.2.2 Providing a stable network identity

StatefulSets provide a stable network identity for each pod through a combination of:

1. **Stable Pod Names**: As mentioned earlier, each pod in a StatefulSet has a stable, unique name based on the StatefulSet name and the pod's ordinal index.

2. **Headless Service**: A StatefulSet requires a Headless Service to provide network identity to the pods. A Headless Service is a Service with `clusterIP: None`. It doesn't provide load balancing or a single service IP. Instead, it creates DNS entries for each pod, allowing them to be addressed individually.

For a StatefulSet named "web" with a Headless Service named "web", the DNS entries would be:

- web-0.web.default.svc.cluster.local
- web-1.web.default.svc.cluster.local
- web-2.web.default.svc.cluster.local

Where "default" is the namespace and "cluster.local" is the cluster domain.

This is illustrated in the following figure:

![Figure 10.3 StatefulSets use a Headless Service to provide stable network identities for pods](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

In this figure, we have a StatefulSet named "web" with three replicas. The pods are named "web-0", "web-1", and "web-2". The Headless Service "web" creates DNS entries for each pod, allowing them to be addressed individually.

### 10.2.3 Providing stable dedicated storage to each pod

StatefulSets provide stable dedicated storage to each pod through PVCs. When a StatefulSet creates a pod, it also creates a PVC for that pod using the PVC template in the StatefulSet specification.

The PVCs are named based on the StatefulSet name and the pod's ordinal index. For example, if a StatefulSet is named "web" and the volume claim template is named "www", the PVCs will be named "www-web-0", "www-web-1", "www-web-2", and so on.

This is illustrated in the following figure:

![Figure 10.4 StatefulSets create PVCs for each pod](https://i.loli.net/2019/05/13/5cd8e1c9c9c9e77693.png)

In this figure, we have a StatefulSet named "web" with three replicas. The StatefulSet creates three PVCs, one for each pod. The PVCs are named "www-web-0", "www-web-1", and "www-web-2".

When a pod is deleted, the StatefulSet doesn't delete the corresponding PVC. This ensures that the pod's data is preserved even if the pod is deleted and recreated. This is important for stateful applications where data persistence is crucial.

### 10.2.4 Understanding StatefulSet guarantees

StatefulSets provide several guarantees that are important for stateful applications:

1. **Stable Network Identity**: Each pod in a StatefulSet has a stable, unique network identity.

2. **Ordered Deployment and Scaling**: Pods are created in order (from 0 to N-1) and deleted in reverse order (from N-1 to 0). This ensures that no two pods with the same identity exist at the same time.

3. **Stable Storage**: Each pod can have its own PVC, which is not deleted when the pod is deleted. This ensures data persistence across pod restarts.

These guarantees make StatefulSets suitable for applications that require one or more of the following:

- Stable, unique network identifiers
- Stable, persistent storage
- Ordered, graceful deployment and scaling
- Ordered, automated rolling updates

## 10.3 Using a StatefulSet

Now that we understand what StatefulSets are and how they work, let's look at how to use them to deploy a stateful application.

### 10.3.1 Creating the app and container image

For this example, we'll create a simple stateful application that demonstrates the features of StatefulSets. The application will:

1. Generate a random value when it starts
2. Store the value in a file on persistent storage
3. Serve the value over HTTP

Here's a simple Node.js application that does this:

```javascript
const http = require('http');
const fs = require('fs');
const os = require('os');

const dataFile = '/data/data.txt';
const hostnameFile = '/data/hostname.txt';

// Generate a random value if the file doesn't exist
if (!fs.existsSync(dataFile)) {
  const value = Math.floor(Math.random() * 1000);
  fs.writeFileSync(dataFile, value.toString());
  console.log(`Generated value: ${value}`);
}

// Store the hostname
fs.writeFileSync(hostnameFile, os.hostname());

// Read the value from the file
const value = fs.readFileSync(dataFile, 'utf8');
const hostname = fs.readFileSync(hostnameFile, 'utf8');

// Create an HTTP server
const server = http.createServer((req, res) => {
  res.statusCode = 200;
  res.setHeader('Content-Type', 'text/plain');
  res.end(`Hello from ${hostname}! My value is ${value}.\n`);
});

// Start the server
server.listen(8080, () => {
  console.log('Server running at http://localhost:8080/');
});
